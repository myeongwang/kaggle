{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59291,"databundleVersionId":6678907,"sourceType":"competition"},{"sourceId":6903820,"sourceType":"datasetVersion","datasetId":3963581},{"sourceId":6971449,"sourceType":"datasetVersion","datasetId":3992884},{"sourceId":6973319,"sourceType":"datasetVersion","datasetId":3949123},{"sourceId":7012215,"sourceType":"datasetVersion","datasetId":3903951},{"sourceId":150384981,"sourceType":"kernelVersion"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LightAutoML installation","metadata":{}},{"cell_type":"code","source":"!pip install --no-index -U --find-links=/kaggle/input/lightautoml-038-dependecies lightautoml==0.3.8\n!pip install --no-index -U --find-links=/kaggle/input/lightautoml-038-dependecies pandas==2.0.3","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-12-02T13:05:17.327396Z","iopub.execute_input":"2023-12-02T13:05:17.327887Z","iopub.status.idle":"2023-12-02T13:06:12.781730Z","shell.execute_reply.started":"2023-12-02T13:05:17.327838Z","shell.execute_reply":"2023-12-02T13:06:12.779994Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/lightautoml-038-dependecies\nProcessing /kaggle/input/lightautoml-038-dependecies/lightautoml-0.3.8-py3-none-any.whl\nProcessing /kaggle/input/lightautoml-038-dependecies/AutoWoE-1.3.2-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\nProcessing /kaggle/input/lightautoml-038-dependecies/cmaes-0.10.0-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.24)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1.2)\nProcessing /kaggle/input/lightautoml-038-dependecies/joblib-1.2.0-py3-none-any.whl (from lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/json2html-1.3.0.tar.gz (from lightautoml==0.3.8)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hProcessing /kaggle/input/lightautoml-038-dependecies/lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (from lightautoml==0.3.8)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.1)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.24.3)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (3.4.0)\nProcessing /kaggle/input/lightautoml-038-dependecies/pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/poetry_core-1.8.1-py3-none-any.whl (from lightautoml==0.3.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (6.0.1)\nRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (1.2.2)\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.12.2)\nRequirement already satisfied: statsmodels<=0.14.0 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (0.14.0)\nRequirement already satisfied: torch<=2.0.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (2.0.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml==0.3.8) (4.66.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/StrEnum-0.4.15-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (3.7.3)\nRequirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (7.4.3)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (2023.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (1.11.3)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinx-7.2.6-py3-none-any.whl (from autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml==0.3.8) (0.2.4)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (0.20.1)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (5.16.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml==0.3.8) (1.16.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml==0.3.8) (0.41.2)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml==0.3.8) (2.8.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml==0.3.8) (3.2.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (0.5.3)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml==0.3.8) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.12)\nRequirement already satisfied: hijri-converter in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (2.3.1)\nRequirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.10/site-packages (from holidays->lightautoml==0.3.8) (0.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml==0.3.8) (2.1.3)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (1.12.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (6.7.0)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml==0.3.8) (2.0.20)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml==0.3.8) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml==0.3.8) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml==0.3.8) (2.0.2)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml==0.3.8) (8.2.3)\nRequirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.0)\nRequirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.2.0)\nRequirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (1.1.3)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml==0.3.8) (2.0.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: Pygments>=2.14 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.16.1)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (0.20.1)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.2.0)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.12.1)\nProcessing /kaggle/input/lightautoml-038-dependecies/alabaster-0.7.13-py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nProcessing /kaggle/input/lightautoml-038-dependecies/imagesize-1.4.1-py2.py3-none-any.whl (from sphinx->autowoe>=1.2->lightautoml==0.3.8)\nRequirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml==0.3.8) (2.31.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml==0.3.8) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->autowoe>=1.2->lightautoml==0.3.8) (2023.7.22)\nBuilding wheels for collected packages: json2html\n  Building wheel for json2html (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7591 sha256=ccefd5221416b77107c3d396761aade6aa056d5fa8879c580065eb67ea6458e0\n  Stored in directory: /root/.cache/pip/wheels/03/04/0d/34912ecabd9128a537a032c0fc15c6c46e734fb5fe3a14536c\nSuccessfully built json2html\nInstalling collected packages: StrEnum, json2html, sphinxcontrib-jsmath, poetry-core, joblib, imagesize, cmaes, alabaster, pandas, lightgbm, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, sphinx, autowoe, lightautoml\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.3.2\n    Uninstalling joblib-1.3.2:\n      Successfully uninstalled joblib-1.3.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.0.3\n    Uninstalling pandas-2.0.3:\n      Successfully uninstalled pandas-2.0.3\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 3.3.2\n    Uninstalling lightgbm-3.3.2:\n      Successfully uninstalled lightgbm-3.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\nfitter 1.6.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-0.7.13 autowoe-1.3.2 cmaes-0.10.0 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8 lightgbm-3.2.1 pandas-1.5.3 poetry-core-1.8.1 sphinx-7.2.6 sphinxcontrib-applehelp-1.0.7 sphinxcontrib-devhelp-1.0.5 sphinxcontrib-htmlhelp-2.0.4 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.6 sphinxcontrib-serializinghtml-1.1.9\nLooking in links: /kaggle/input/lightautoml-038-dependecies\nProcessing /kaggle/input/lightautoml-038-dependecies/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==2.0.3) (1.24.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3) (1.16.0)\nInstalling collected packages: pandas\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Uninstalling pandas-1.5.3:\n      Successfully uninstalled pandas-1.5.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.10.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\nfitter 1.6.0 requires joblib<2.0.0,>=1.3.1, but you have joblib 1.2.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nlightautoml 0.3.8 requires pandas<2.0.0, but you have pandas 2.0.3 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pandas-2.0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"%matplotlib inline\nimport gc\nimport os\nimport itertools\nimport pickle\nimport re\nimport time\nfrom random import choice, choices\nfrom functools import reduce\nfrom tqdm import tqdm\nfrom itertools import cycle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom functools import reduce\nfrom itertools import cycle\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nfrom sklearn import metrics, model_selection, preprocessing, linear_model, ensemble, decomposition, tree\nimport lightgbm as lgb\nimport torch","metadata":{"papermill":{"duration":4.154316,"end_time":"2023-11-05T19:55:14.77427","exception":false,"start_time":"2023-11-05T19:55:10.619954","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:40:35.816326Z","iopub.execute_input":"2023-12-02T12:40:35.816723Z","iopub.status.idle":"2023-12-02T12:40:35.828165Z","shell.execute_reply.started":"2023-12-02T12:40:35.816692Z","shell.execute_reply":"2023-12-02T12:40:35.826888Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{"papermill":{"duration":0.007333,"end_time":"2023-11-05T19:55:14.789479","exception":false,"start_time":"2023-11-05T19:55:14.782146","status":"completed"},"tags":[]}},{"cell_type":"code","source":"INPUT_DIR = '../input/linking-writing-processes-to-writing-quality'\ntrain_logs = pd.read_csv(f'{INPUT_DIR}/train_logs.csv')\ntrain_scores = pd.read_csv(f'{INPUT_DIR}/train_scores.csv')\ntest_logs = pd.read_csv(f'{INPUT_DIR}/test_logs.csv')\nss_df = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')","metadata":{"papermill":{"duration":17.101649,"end_time":"2023-11-05T19:55:31.898771","exception":false,"start_time":"2023-11-05T19:55:14.797122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:40:43.314253Z","iopub.execute_input":"2023-12-02T12:40:43.314689Z","iopub.status.idle":"2023-12-02T12:41:00.479917Z","shell.execute_reply.started":"2023-12-02T12:40:43.314657Z","shell.execute_reply":"2023-12-02T12:41:00.478319Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_logs","metadata":{"execution":{"iopub.status.busy":"2023-12-02T12:44:53.954790Z","iopub.execute_input":"2023-12-02T12:44:53.955250Z","iopub.status.idle":"2023-12-02T12:44:53.983152Z","shell.execute_reply.started":"2023-12-02T12:44:53.955215Z","shell.execute_reply":"2023-12-02T12:44:53.981885Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"               id  event_id  down_time  up_time  action_time       activity  \\\n0        001519c8         1       4526     4557           31  Nonproduction   \n1        001519c8         2       4558     4962          404  Nonproduction   \n2        001519c8         3     106571   106571            0  Nonproduction   \n3        001519c8         4     106686   106777           91          Input   \n4        001519c8         5     107196   107323          127          Input   \n...           ...       ...        ...      ...          ...            ...   \n8405893  fff05981      3615    2063944  2064440          496  Nonproduction   \n8405894  fff05981      3616    2064497  2064497            0  Nonproduction   \n8405895  fff05981      3617    2064657  2064765          108        Replace   \n8405896  fff05981      3618    2069186  2069259           73  Nonproduction   \n8405897  fff05981      3619    2070065  2070133           68          Input   \n\n        down_event   up_event text_change  cursor_position  word_count  \n0        Leftclick  Leftclick    NoChange                0           0  \n1        Leftclick  Leftclick    NoChange                0           0  \n2            Shift      Shift    NoChange                0           0  \n3                q          q           q                1           1  \n4                q          q           q                2           1  \n...            ...        ...         ...              ...         ...  \n8405893  Leftclick  Leftclick    NoChange             1031         240  \n8405894      Shift      Shift    NoChange             1031         240  \n8405895          q          q      q => q             1031         240  \n8405896  Leftclick  Leftclick    NoChange             1028         240  \n8405897          .          .           .             1029         240  \n\n[8405898 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>1</td>\n      <td>4526</td>\n      <td>4557</td>\n      <td>31</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001519c8</td>\n      <td>2</td>\n      <td>4558</td>\n      <td>4962</td>\n      <td>404</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001519c8</td>\n      <td>3</td>\n      <td>106571</td>\n      <td>106571</td>\n      <td>0</td>\n      <td>Nonproduction</td>\n      <td>Shift</td>\n      <td>Shift</td>\n      <td>NoChange</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001519c8</td>\n      <td>4</td>\n      <td>106686</td>\n      <td>106777</td>\n      <td>91</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001519c8</td>\n      <td>5</td>\n      <td>107196</td>\n      <td>107323</td>\n      <td>127</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8405893</th>\n      <td>fff05981</td>\n      <td>3615</td>\n      <td>2063944</td>\n      <td>2064440</td>\n      <td>496</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>1031</td>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>8405894</th>\n      <td>fff05981</td>\n      <td>3616</td>\n      <td>2064497</td>\n      <td>2064497</td>\n      <td>0</td>\n      <td>Nonproduction</td>\n      <td>Shift</td>\n      <td>Shift</td>\n      <td>NoChange</td>\n      <td>1031</td>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>8405895</th>\n      <td>fff05981</td>\n      <td>3617</td>\n      <td>2064657</td>\n      <td>2064765</td>\n      <td>108</td>\n      <td>Replace</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q =&gt; q</td>\n      <td>1031</td>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>8405896</th>\n      <td>fff05981</td>\n      <td>3618</td>\n      <td>2069186</td>\n      <td>2069259</td>\n      <td>73</td>\n      <td>Nonproduction</td>\n      <td>Leftclick</td>\n      <td>Leftclick</td>\n      <td>NoChange</td>\n      <td>1028</td>\n      <td>240</td>\n    </tr>\n    <tr>\n      <th>8405897</th>\n      <td>fff05981</td>\n      <td>3619</td>\n      <td>2070065</td>\n      <td>2070133</td>\n      <td>68</td>\n      <td>Input</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>1029</td>\n      <td>240</td>\n    </tr>\n  </tbody>\n</table>\n<p>8405898 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_scores","metadata":{"execution":{"iopub.status.busy":"2023-12-02T12:44:47.453523Z","iopub.execute_input":"2023-12-02T12:44:47.453995Z","iopub.status.idle":"2023-12-02T12:44:47.471053Z","shell.execute_reply.started":"2023-12-02T12:44:47.453960Z","shell.execute_reply":"2023-12-02T12:44:47.469570Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"            id  score\n0     001519c8    3.5\n1     0022f953    3.5\n2     0042269b    6.0\n3     0059420b    2.0\n4     0075873a    4.0\n...        ...    ...\n2466  ffb8c745    3.5\n2467  ffbef7e5    4.0\n2468  ffccd6fd    1.5\n2469  ffec5b38    5.0\n2470  fff05981    4.0\n\n[2471 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>001519c8</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022f953</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0042269b</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0059420b</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0075873a</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2466</th>\n      <td>ffb8c745</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>2467</th>\n      <td>ffbef7e5</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2468</th>\n      <td>ffccd6fd</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>2469</th>\n      <td>ffec5b38</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2470</th>\n      <td>fff05981</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2471 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_logs","metadata":{"execution":{"iopub.status.busy":"2023-12-02T12:43:04.778607Z","iopub.execute_input":"2023-12-02T12:43:04.779059Z","iopub.status.idle":"2023-12-02T12:43:04.797191Z","shell.execute_reply.started":"2023-12-02T12:43:04.779025Z","shell.execute_reply":"2023-12-02T12:43:04.795954Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         id  event_id  down_time  up_time  action_time activity down_event  \\\n0  0000aaaa         1     338433   338518           85    Input      Space   \n1  0000aaaa         2     760073   760160           87    Input      Space   \n2  2222bbbb         1     711956   712023           67    Input          q   \n3  2222bbbb         2     290502   290548           46    Input          q   \n4  4444cccc         1     635547   635641           94    Input      Space   \n5  4444cccc         2     184996   185052           56    Input          q   \n\n  up_event text_change  cursor_position  word_count  \n0    Space                            0           0  \n1    Space                            1           0  \n2        q           q                0           1  \n3        q           q                1           1  \n4    Space                            0           0  \n5        q           q                1           1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>event_id</th>\n      <th>down_time</th>\n      <th>up_time</th>\n      <th>action_time</th>\n      <th>activity</th>\n      <th>down_event</th>\n      <th>up_event</th>\n      <th>text_change</th>\n      <th>cursor_position</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>1</td>\n      <td>338433</td>\n      <td>338518</td>\n      <td>85</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000aaaa</td>\n      <td>2</td>\n      <td>760073</td>\n      <td>760160</td>\n      <td>87</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222bbbb</td>\n      <td>1</td>\n      <td>711956</td>\n      <td>712023</td>\n      <td>67</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2222bbbb</td>\n      <td>2</td>\n      <td>290502</td>\n      <td>290548</td>\n      <td>46</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4444cccc</td>\n      <td>1</td>\n      <td>635547</td>\n      <td>635641</td>\n      <td>94</td>\n      <td>Input</td>\n      <td>Space</td>\n      <td>Space</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4444cccc</td>\n      <td>2</td>\n      <td>184996</td>\n      <td>185052</td>\n      <td>56</td>\n      <td>Input</td>\n      <td>q</td>\n      <td>q</td>\n      <td>q</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_essays = pd.read_csv('../input/writing-quality-challenge-constructed-essays/train_essays_02.csv')\ntrain_essays.index = train_essays[\"Unnamed: 0\"]\ntrain_essays.index.name = None\ntrain_essays.drop(columns=[\"Unnamed: 0\"], inplace=True)\ntrain_essays.head()","metadata":{"papermill":{"duration":0.155263,"end_time":"2023-11-05T19:55:32.062212","exception":false,"start_time":"2023-11-05T19:55:31.906949","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:41:06.412788Z","iopub.execute_input":"2023-12-02T12:41:06.413262Z","iopub.status.idle":"2023-12-02T12:41:06.560156Z","shell.execute_reply.started":"2023-12-02T12:41:06.413226Z","shell.execute_reply":"2023-12-02T12:41:06.558943Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                      essay\n001519c8  qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...\n0022f953  qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...\n0042269b  qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...\n0059420b  qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...\n0075873a  qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>001519c8</th>\n      <td>qqqqqqqqq qq qqqqq qq qqqq qqqq.  qqqqqq qqq q...</td>\n    </tr>\n    <tr>\n      <th>0022f953</th>\n      <td>qqqq qq qqqqqqqqqqq ? qq qq qqq qqq qqq, qqqqq...</td>\n    </tr>\n    <tr>\n      <th>0042269b</th>\n      <td>qqqqqqqqqqq qq qqqqq qqqqqqqqq qq qqqqqqqqqqq ...</td>\n    </tr>\n    <tr>\n      <th>0059420b</th>\n      <td>qq qqqqqqq qqqqqq qqqqqqqqqqqqq qqqq q qqqq qq...</td>\n    </tr>\n    <tr>\n      <th>0075873a</th>\n      <td>qqqqqqqqqqq qq qqq qqqqq qq qqqqqqqqqq, qqq qq...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{"papermill":{"duration":0.008126,"end_time":"2023-11-05T19:55:32.078474","exception":false,"start_time":"2023-11-05T19:55:32.070348","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Function to construct essays copied from here (small adjustments): https://www.kaggle.com/code/kawaiicoderuwu/essay-contructor\n\ndef getEssays(df):\n    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']]\n    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n    lastIndex = 0\n    essaySeries = pd.Series()\n    for index, valCount in enumerate(valCountsArr):\n        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n        lastIndex += valCount\n        essayText = \"\"\n        for Input in currTextInput.values:\n            if Input[0] == 'Replace':\n                replaceTxt = Input[2].split(' => ')\n                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] +\\\n                essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n                continue\n            if Input[0] == 'Paste':\n                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n                continue\n            if Input[0] == 'Remove/Cut':\n                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n                continue\n            if \"M\" in Input[0]:\n                croppedTxt = Input[0][10:]\n                splitTxt = croppedTxt.split(' To ')\n                valueArr = [item.split(', ') for item in splitTxt]\n                moveData = (int(valueArr[0][0][1:]), \n                            int(valueArr[0][1][:-1]), \n                            int(valueArr[1][0][1:]), \n                            int(valueArr[1][1][:-1]))\n                if moveData[0] != moveData[2]:\n                    if moveData[0] < moveData[2]:\n                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] +\\\n                        essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n                    else:\n                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] +\\\n                        essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n                continue\n            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n        essaySeries[index] = essayText\n    essaySeries.index =  textInputDf['id'].unique()\n    return pd.DataFrame(essaySeries, columns=['essay'])","metadata":{"papermill":{"duration":0.029497,"end_time":"2023-11-05T19:55:32.116127","exception":false,"start_time":"2023-11-05T19:55:32.08663","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:48:37.096259Z","iopub.execute_input":"2023-12-02T12:48:37.096720Z","iopub.status.idle":"2023-12-02T12:48:37.116530Z","shell.execute_reply.started":"2023-12-02T12:48:37.096685Z","shell.execute_reply":"2023-12-02T12:48:37.115070Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Helper functions\n\ndef q1(x):\n    return x.quantile(0.25)\ndef q3(x):\n    return x.quantile(0.75)","metadata":{"papermill":{"duration":0.016764,"end_time":"2023-11-05T19:55:32.141238","exception":false,"start_time":"2023-11-05T19:55:32.124474","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:48:39.317772Z","iopub.execute_input":"2023-12-02T12:48:39.319026Z","iopub.status.idle":"2023-12-02T12:48:39.325606Z","shell.execute_reply.started":"2023-12-02T12:48:39.318976Z","shell.execute_reply":"2023-12-02T12:48:39.324239Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', pd.DataFrame.kurt, 'sum']\n\ndef split_essays_into_sentences(df):\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',x))\n    essay_df = essay_df.explode('sent')\n    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n','').strip())\n    # Number of characters in sentences\n    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n    # Number of words in sentences\n    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.sent_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_sentence_aggregations(df):\n    sent_agg_df = pd.concat(\n        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    )\n    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n    sent_agg_df['id'] = sent_agg_df.index\n    sent_agg_df = sent_agg_df.reset_index(drop=True)\n    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n    return sent_agg_df\n\ndef split_essays_into_paragraphs(df):\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: x.split('\\n'))\n    essay_df = essay_df.explode('paragraph')\n    # Number of characters in paragraphs\n    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n    # Number of words in paragraphs\n    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.paragraph_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_paragraph_aggregations(df):\n    paragraph_agg_df = pd.concat(\n        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    ) \n    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n    paragraph_agg_df['id'] = paragraph_agg_df.index\n    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n    return paragraph_agg_df","metadata":{"papermill":{"duration":0.031457,"end_time":"2023-11-05T19:55:32.18096","exception":false,"start_time":"2023-11-05T19:55:32.149503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:48:53.292094Z","iopub.execute_input":"2023-12-02T12:48:53.292529Z","iopub.status.idle":"2023-12-02T12:48:53.331193Z","shell.execute_reply.started":"2023-12-02T12:48:53.292497Z","shell.execute_reply":"2023-12-02T12:48:53.329809Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Sentence features for train dataset\ntrain_sent_df = split_essays_into_sentences(train_essays)\ntrain_sent_agg_df = compute_sentence_aggregations(train_sent_df)\nplt.figure(figsize=(15, 1.5))\nplt.boxplot(x=train_sent_df.sent_len, vert=False, labels=['Sentence length'])\nplt.show()","metadata":{"papermill":{"duration":8.195247,"end_time":"2023-11-05T19:55:40.384252","exception":false,"start_time":"2023-11-05T19:55:32.189005","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:50:38.562789Z","iopub.execute_input":"2023-12-02T12:50:38.563238Z","iopub.status.idle":"2023-12-02T12:50:47.198673Z","shell.execute_reply.started":"2023-12-02T12:50:38.563202Z","shell.execute_reply":"2023-12-02T12:50:47.197304Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x150 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Paragraph features for train dataset\ntrain_paragraph_df = split_essays_into_paragraphs(train_essays)\ntrain_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)\nplt.figure(figsize=(15, 1.5))\nplt.boxplot(x=train_paragraph_df.paragraph_len, vert=False, labels=['Paragraph length'])\nplt.show()","metadata":{"papermill":{"duration":8.110471,"end_time":"2023-11-05T19:55:48.50333","exception":false,"start_time":"2023-11-05T19:55:40.392859","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:50:48.936698Z","iopub.execute_input":"2023-12-02T12:50:48.937168Z","iopub.status.idle":"2023-12-02T12:50:57.075415Z","shell.execute_reply.started":"2023-12-02T12:50:48.937131Z","shell.execute_reply":"2023-12-02T12:50:57.074029Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x150 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Features for test dataset\ntest_essays = getEssays(test_logs)\ntest_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essays))\ntest_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essays))","metadata":{"papermill":{"duration":0.09158,"end_time":"2023-11-05T19:55:48.603596","exception":false,"start_time":"2023-11-05T19:55:48.512016","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:51:16.622770Z","iopub.execute_input":"2023-12-02T12:51:16.623220Z","iopub.status.idle":"2023-12-02T12:51:16.706079Z","shell.execute_reply.started":"2023-12-02T12:51:16.623186Z","shell.execute_reply":"2023-12-02T12:51:16.704806Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# The following code comes almost Abdullah's notebook: https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs\n# Abdullah's code is based on work shared in previous notebooks (e.g., https://www.kaggle.com/code/hengzheng/link-writing-simple-lgbm-baseline)\n\nfrom collections import defaultdict\n\nclass Preprocessor:\n    \n    def __init__(self, seed):\n        self.seed = seed\n        \n        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n        \n        self.idf = defaultdict(float)\n    \n    def activity_counts(self, df):\n        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['activity'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.activities:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n\n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n\n        return ret\n\n    def event_counts(self, df, colname):\n        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df[colname].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.events:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n            \n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n\n        return ret\n\n    def text_change_counts(self, df):\n        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['text_change'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.text_changes:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n            \n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n            \n        return ret\n\n    def match_punctuations(self, df):\n        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['down_event'].values):\n            cnt = 0\n            items = list(Counter(li).items())\n            for item in items:\n                k, v = item[0], item[1]\n                if k in self.punctuations:\n                    cnt += v\n            ret.append(cnt)\n        ret = pd.DataFrame({'punct_cnt': ret})\n        return ret\n\n    def get_input_words(self, df):\n        tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df.drop(['text_change'], axis=1, inplace=True)\n        return tmp_df\n    \n    def make_feats(self, df):\n        \n        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n        \n        print(\"Engineering time data\")\n        for gap in self.gaps:\n            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n\n        print(\"Engineering cursor position data\")\n        for gap in self.gaps:\n            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n\n        print(\"Engineering word count data\")\n        for gap in self.gaps:\n            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n        \n        print(\"Engineering statistical summaries for features\")\n        feats_stat = [\n            ('event_id', ['max']),\n            ('up_time', ['max']),\n            ('action_time', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n            ('activity', ['nunique']),\n            ('down_event', ['nunique']),\n            ('up_event', ['nunique']),\n            ('text_change', ['nunique']),\n            ('cursor_position', ['nunique', 'max', 'quantile', 'sem', 'mean']),\n            ('word_count', ['nunique', 'max', 'quantile', 'sem', 'mean'])]\n        for gap in self.gaps:\n            feats_stat.extend([\n                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n                (f'word_count_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt])\n            ])\n        \n        pbar = tqdm(feats_stat)\n        for item in pbar:\n            colname, methods = item[0], item[1]\n            for method in methods:\n                pbar.set_postfix()\n                if isinstance(method, str):\n                    method_name = method\n                else:\n                    method_name = method.__name__\n                pbar.set_postfix(column=colname, method=method_name)\n                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n                feats = feats.merge(tmp_df, on='id', how='left')\n\n        print(\"Engineering activity counts data\")\n        tmp_df = self.activity_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering event counts data\")\n        tmp_df = self.event_counts(df, 'down_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        tmp_df = self.event_counts(df, 'up_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering text change counts data\")\n        tmp_df = self.text_change_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering punctuation counts data\")\n        tmp_df = self.match_punctuations(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n\n        print(\"Engineering input words data\")\n        tmp_df = self.get_input_words(df)\n        feats = pd.merge(feats, tmp_df, on='id', how='left')\n\n        print(\"Engineering ratios data\")\n        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n\n        return feats","metadata":{"papermill":{"duration":0.070872,"end_time":"2023-11-05T19:55:48.683261","exception":false,"start_time":"2023-11-05T19:55:48.612389","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:51:21.085996Z","iopub.execute_input":"2023-12-02T12:51:21.086832Z","iopub.status.idle":"2023-12-02T12:51:21.150159Z","shell.execute_reply.started":"2023-12-02T12:51:21.086789Z","shell.execute_reply":"2023-12-02T12:51:21.148197Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"preprocessor = Preprocessor(seed=42)\ntrain_feats = preprocessor.make_feats(train_logs)\ntest_feats = preprocessor.make_feats(test_logs)\nnan_cols = train_feats.columns[train_feats.isna().any()].tolist()\ntrain_feats = train_feats.drop(columns=nan_cols)\ntest_feats = test_feats.drop(columns=nan_cols)","metadata":{"papermill":{"duration":370.664062,"end_time":"2023-11-05T20:01:59.356059","exception":false,"start_time":"2023-11-05T19:55:48.691997","status":"completed"},"tags":[],"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-12-02T12:51:28.610529Z","iopub.execute_input":"2023-12-02T12:51:28.610982Z","iopub.status.idle":"2023-12-02T12:57:43.352050Z","shell.execute_reply.started":"2023-12-02T12:51:28.610947Z","shell.execute_reply":"2023-12-02T12:57:43.350355Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Engineering time data\nEngineering cursor position data\nEngineering word count data\nEngineering statistical summaries for features\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 33/33 [04:59<00:00,  9.07s/it, column=word_count_change100, method=kurt]         \n","output_type":"stream"},{"name":"stdout","text":"Engineering activity counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 4557.22it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering event counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 4696.82it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n100%|██████████| 2471/2471 [00:00<00:00, 4676.53it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering text change counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 4874.26it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering punctuation counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2471/2471 [00:00<00:00, 4659.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Engineering input words data\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_47/3946551957.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n/tmp/ipykernel_47/3946551957.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n","output_type":"stream"},{"name":"stdout","text":"Engineering ratios data\nEngineering time data\nEngineering cursor position data\nEngineering word count data\nEngineering statistical summaries for features\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 33/33 [00:02<00:00, 15.03it/s, column=word_count_change100, method=kurt]         \n","output_type":"stream"},{"name":"stdout","text":"Engineering activity counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 17213.29it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering event counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 20327.81it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n100%|██████████| 3/3 [00:00<00:00, 12169.16it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering text change counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 13934.56it/s]\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Engineering punctuation counts data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [00:00<00:00, 7129.13it/s]\n/tmp/ipykernel_47/3946551957.py:221: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:222: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n/tmp/ipykernel_47/3946551957.py:223: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n/tmp/ipykernel_47/3946551957.py:224: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n","output_type":"stream"},{"name":"stdout","text":"Engineering input words data\nEngineering ratios data\n","output_type":"stream"}]},{"cell_type":"code","source":"# Code for additional aggregations comes from here: https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs\n\ntrain_agg_fe_df = train_logs.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(\n    ['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntrain_agg_fe_df.columns = ['_'.join(x) for x in train_agg_fe_df.columns]\ntrain_agg_fe_df = train_agg_fe_df.add_prefix(\"tmp_\")\ntrain_agg_fe_df.reset_index(inplace=True)\n\ntest_agg_fe_df = test_logs.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(\n    ['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntest_agg_fe_df.columns = ['_'.join(x) for x in test_agg_fe_df.columns]\ntest_agg_fe_df = test_agg_fe_df.add_prefix(\"tmp_\")\ntest_agg_fe_df.reset_index(inplace=True)\n\ntrain_feats = train_feats.merge(train_agg_fe_df, on='id', how='left')\ntest_feats = test_feats.merge(test_agg_fe_df, on='id', how='left')","metadata":{"papermill":{"duration":5.754153,"end_time":"2023-11-05T20:02:05.211536","exception":false,"start_time":"2023-11-05T20:01:59.457383","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:57:49.773130Z","iopub.execute_input":"2023-12-02T12:57:49.773563Z","iopub.status.idle":"2023-12-02T12:57:57.588128Z","shell.execute_reply.started":"2023-12-02T12:57:49.773529Z","shell.execute_reply":"2023-12-02T12:57:57.586850Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Code for creating these features comes from here: https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs\n# Idea is based on features introduced in Section 3 of this research paper: https://files.eric.ed.gov/fulltext/ED592674.pdf\n\ndata = []\n\nfor logs in [train_logs, test_logs]:\n    logs['up_time_lagged'] = logs.groupby('id')['up_time'].shift(1).fillna(logs['down_time'])\n    logs['time_diff'] = abs(logs['down_time'] - logs['up_time_lagged']) / 1000\n\n    group = logs.groupby('id')['time_diff']\n    largest_lantency = group.max()\n    smallest_lantency = group.min()\n    median_lantency = group.median()\n    initial_pause = logs.groupby('id')['down_time'].first() / 1000\n    pauses_half_sec = group.apply(lambda x: ((x > 0.5) & (x < 1)).sum())\n    pauses_1_sec = group.apply(lambda x: ((x > 1) & (x < 1.5)).sum())\n    pauses_1_half_sec = group.apply(lambda x: ((x > 1.5) & (x < 2)).sum())\n    pauses_2_sec = group.apply(lambda x: ((x > 2) & (x < 3)).sum())\n    pauses_3_sec = group.apply(lambda x: (x > 3).sum())\n\n    data.append(pd.DataFrame({\n        'id': logs['id'].unique(),\n        'largest_lantency': largest_lantency,\n        'smallest_lantency': smallest_lantency,\n        'median_lantency': median_lantency,\n        'initial_pause': initial_pause,\n        'pauses_half_sec': pauses_half_sec,\n        'pauses_1_sec': pauses_1_sec,\n        'pauses_1_half_sec': pauses_1_half_sec,\n        'pauses_2_sec': pauses_2_sec,\n        'pauses_3_sec': pauses_3_sec,\n    }).reset_index(drop=True))\n\ntrain_eD592674, test_eD592674 = data\n\ntrain_feats = train_feats.merge(train_eD592674, on='id', how='left')\ntest_feats = test_feats.merge(test_eD592674, on='id', how='left')\ntrain_feats = train_feats.merge(train_scores, on='id', how='left')","metadata":{"papermill":{"duration":11.523742,"end_time":"2023-11-05T20:02:16.835416","exception":false,"start_time":"2023-11-05T20:02:05.311674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:58:01.402375Z","iopub.execute_input":"2023-12-02T12:58:01.402766Z","iopub.status.idle":"2023-12-02T12:58:13.634416Z","shell.execute_reply.started":"2023-12-02T12:58:01.402737Z","shell.execute_reply":"2023-12-02T12:58:13.632944Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Adding the additional features to the original feature set\n\ntrain_feats = train_feats.merge(train_sent_agg_df, on='id', how='left')\ntrain_feats = train_feats.merge(train_paragraph_agg_df, on='id', how='left')\ntest_feats = test_feats.merge(test_sent_agg_df, on='id', how='left')\ntest_feats = test_feats.merge(test_paragraph_agg_df, on='id', how='left')","metadata":{"papermill":{"duration":0.139952,"end_time":"2023-11-05T20:02:17.075043","exception":false,"start_time":"2023-11-05T20:02:16.935091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:58:21.722889Z","iopub.execute_input":"2023-12-02T12:58:21.723319Z","iopub.status.idle":"2023-12-02T12:58:21.768778Z","shell.execute_reply.started":"2023-12-02T12:58:21.723282Z","shell.execute_reply":"2023-12-02T12:58:21.767777Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"target_col = ['score']\ndrop_cols = ['id']\ntrain_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]","metadata":{"papermill":{"duration":0.111533,"end_time":"2023-11-05T20:02:17.288094","exception":false,"start_time":"2023-11-05T20:02:17.176561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-02T12:58:26.841774Z","iopub.execute_input":"2023-12-02T12:58:26.842856Z","iopub.status.idle":"2023-12-02T12:58:26.847779Z","shell.execute_reply.started":"2023-12-02T12:58:26.842807Z","shell.execute_reply":"2023-12-02T12:58:26.846963Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len(test_feats)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T12:58:29.284526Z","iopub.execute_input":"2023-12-02T12:58:29.285216Z","iopub.status.idle":"2023-12-02T12:58:29.292684Z","shell.execute_reply.started":"2023-12-02T12:58:29.285180Z","shell.execute_reply":"2023-12-02T12:58:29.291453Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"markdown","source":"# LightGBM train and predict","metadata":{}},{"cell_type":"code","source":"OOF_PREDS = np.zeros((len(train_feats), 2))\nTEST_PREDS = np.zeros((len(test_feats), 2))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T12:58:33.924377Z","iopub.execute_input":"2023-12-02T12:58:33.924823Z","iopub.status.idle":"2023-12-02T12:58:33.930525Z","shell.execute_reply.started":"2023-12-02T12:58:33.924789Z","shell.execute_reply":"2023-12-02T12:58:33.929348Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Code comes from here: https://www.kaggle.com/code/abdullahmeda/enter-ing-the-timeseries-space-sec-3-new-aggs\n\nmodels_dict = {}\nscores = []\n\ntest_predict_list = []\nbest_params = {'reg_alpha': 0.007678095440286993, \n               'reg_lambda': 0.34230534302168353, \n               'colsample_bytree': 0.627061253588415, \n               'subsample': 0.854942238828458, \n               'learning_rate': 0.04,   #0.038697981947473245, \n               'num_leaves': 22, \n               'max_depth': 37, \n               'min_child_samples': 18,\n               'n_jobs':4\n              }\n\nfor i in range(5): \n    kf = model_selection.KFold(n_splits=10, random_state=42 + i, shuffle=True)\n    oof_valid_preds = np.zeros(train_feats.shape[0])\n    X_test = test_feats[train_cols]\n    for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n        \n        X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n        X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n        params = {\n            \"objective\": \"regression\",\n            \"metric\": \"rmse\",\n            'random_state': 42,\n            \"n_estimators\" : 12001,\n            \"verbosity\": -1,\n            **best_params\n        }\n        model = lgb.LGBMRegressor(**params)\n        early_stopping_callback = lgb.early_stopping(100, first_metric_only=True, verbose=False)\n        \n        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],  \n                  callbacks=[early_stopping_callback],\n        )\n        valid_predict = model.predict(X_valid)\n        oof_valid_preds[valid_idx] = valid_predict\n        OOF_PREDS[valid_idx, 0] += valid_predict / 5\n        test_predict = model.predict(X_test)\n        TEST_PREDS[:, 0] += test_predict / 5 / 10\n        test_predict_list.append(test_predict)\n        score = metrics.mean_squared_error(y_valid, valid_predict, squared=False)\n        models_dict[f'{fold}_{i}'] = model\n\n    oof_score = metrics.mean_squared_error(train_feats[target_col], oof_valid_preds, squared=False)\n    scores.append(oof_score)","metadata":{"papermill":{"duration":382.8295,"end_time":"2023-11-05T20:08:40.219879","exception":false,"start_time":"2023-11-05T20:02:17.390379","status":"completed"},"scrolled":true,"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-12-02T12:58:39.715005Z","iopub.execute_input":"2023-12-02T12:58:39.715486Z","iopub.status.idle":"2023-12-02T13:03:42.143623Z","shell.execute_reply.started":"2023-12-02T12:58:39.715451Z","shell.execute_reply":"2023-12-02T13:03:42.142321Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print('OOF metric LGBM = {:.5f}'.format(metrics.mean_squared_error(train_feats[target_col], \n                                                                   OOF_PREDS[:, 0], \n                                                                   squared=False)))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:04:59.270431Z","iopub.execute_input":"2023-12-02T13:04:59.270939Z","iopub.status.idle":"2023-12-02T13:04:59.281216Z","shell.execute_reply.started":"2023-12-02T13:04:59.270901Z","shell.execute_reply":"2023-12-02T13:04:59.279632Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"OOF metric LGBM = 0.61522\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LightAutoML NN (DenseLight) prediction","metadata":{}},{"cell_type":"code","source":"from lightautoml.automl.presets.tabular_presets import TabularAutoML\nfrom lightautoml.tasks import Task\nimport joblib\n\n# def use_plr(USE_PLR):\n#     if USE_PLR:\n#         return \"plr\"\n#     else:\n#         return \"cont\"","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:12:19.545582Z","iopub.execute_input":"2023-12-02T13:12:19.546093Z","iopub.status.idle":"2023-12-02T13:12:58.566383Z","shell.execute_reply.started":"2023-12-02T13:12:19.546052Z","shell.execute_reply":"2023-12-02T13:12:58.565360Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    oof_pred, automl = joblib.load('/kaggle/input/linkinglamamodels/oof_and_lama_denselight_{}.pkl'.format(i))\n    OOF_PREDS[:, 1] += oof_pred / 3\n    TEST_PREDS[:, 1] += automl.predict(test_feats[train_cols]).data[:, 0] / 3","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-12-02T13:13:25.905733Z","iopub.execute_input":"2023-12-02T13:13:25.906711Z","iopub.status.idle":"2023-12-02T13:14:35.450324Z","shell.execute_reply.started":"2023-12-02T13:13:25.906668Z","shell.execute_reply":"2023-12-02T13:14:35.449131Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator QuantileTransformer from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator QuantileTransformer from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator QuantileTransformer from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"print('OOF metric LightAutoML_NN = {:.5f}'.format(metrics.mean_squared_error(train_feats[target_col], \n                                                                               OOF_PREDS[:, 1], \n                                                                               squared=False)))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:22:25.198355Z","iopub.execute_input":"2023-12-02T13:22:25.198924Z","iopub.status.idle":"2023-12-02T13:22:25.211048Z","shell.execute_reply.started":"2023-12-02T13:22:25.198852Z","shell.execute_reply":"2023-12-02T13:22:25.209761Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"OOF metric LightAutoML_NN = 0.61386\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Blending","metadata":{}},{"cell_type":"code","source":"best_sc = 1\nfor w in np.arange(0, 1.01, 0.001):\n    sc = metrics.mean_squared_error(train_feats[target_col], \n                                    w * OOF_PREDS[:, 0] + (1-w) * OOF_PREDS[:, 1], \n                                    squared=False)\n    if sc < best_sc:\n        best_sc = sc\n        best_w = w\n        \nprint('Composition OOF score = {:.5f}'.format(best_sc))\nprint('Composition best W = {:.3f}'.format(best_w))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:22:36.668558Z","iopub.execute_input":"2023-12-02T13:22:36.669027Z","iopub.status.idle":"2023-12-02T13:22:38.914753Z","shell.execute_reply.started":"2023-12-02T13:22:36.668979Z","shell.execute_reply":"2023-12-02T13:22:38.913552Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Composition OOF score = 0.60851\nComposition best W = 0.472\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submission creation","metadata":{}},{"cell_type":"code","source":"W = [best_w, 1 - best_w]\nprint(W)\ntest_preds = TEST_PREDS[:, 0] * W[0] + TEST_PREDS[:, 1] * W[1]\ntest_preds","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:22:47.527256Z","iopub.execute_input":"2023-12-02T13:22:47.527707Z","iopub.status.idle":"2023-12-02T13:22:47.537416Z","shell.execute_reply.started":"2023-12-02T13:22:47.527672Z","shell.execute_reply":"2023-12-02T13:22:47.536174Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"[0.47200000000000003, 0.528]\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([1.66823226, 0.99674628, 0.95888981])"},"metadata":{}}]},{"cell_type":"code","source":"test_feats['score'] = test_preds\nsub1 = test_feats[['id', 'score']]\n#test_feats[['id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:22:51.184053Z","iopub.execute_input":"2023-12-02T13:22:51.185163Z","iopub.status.idle":"2023-12-02T13:22:51.193266Z","shell.execute_reply.started":"2023-12-02T13:22:51.185127Z","shell.execute_reply":"2023-12-02T13:22:51.192415Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/1024135510.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  test_feats['score'] = test_preds\n","output_type":"stream"}]},{"cell_type":"code","source":"sub1","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:22:55.290952Z","iopub.execute_input":"2023-12-02T13:22:55.291367Z","iopub.status.idle":"2023-12-02T13:22:55.307694Z","shell.execute_reply.started":"2023-12-02T13:22:55.291333Z","shell.execute_reply":"2023-12-02T13:22:55.306328Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"         id     score\n0  0000aaaa  1.668232\n1  2222bbbb  0.996746\n2  4444cccc  0.958890","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>1.668232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2222bbbb</td>\n      <td>0.996746</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4444cccc</td>\n      <td>0.958890</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sub1.to_csv('submission.csv',index=False\n           )","metadata":{"execution":{"iopub.status.busy":"2023-12-02T13:24:13.034913Z","iopub.execute_input":"2023-12-02T13:24:13.035313Z","iopub.status.idle":"2023-12-02T13:24:13.044548Z","shell.execute_reply.started":"2023-12-02T13:24:13.035282Z","shell.execute_reply":"2023-12-02T13:24:13.043234Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Saving OOFs and test predictions","metadata":{}},{"cell_type":"code","source":"joblib.dump((OOF_PREDS, TEST_PREDS), 'OOF_and_TEST_preds.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-11-22T23:40:10.960093Z","iopub.execute_input":"2023-11-22T23:40:10.960517Z","iopub.status.idle":"2023-11-22T23:40:10.969079Z","shell.execute_reply.started":"2023-11-22T23:40:10.960484Z","shell.execute_reply":"2023-11-22T23:40:10.968128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Public LGBM","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport gc\nimport ctypes\ndef clean_memory():\n    gc.collect()\n    ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n    torch.cuda.empty_cache()\nclean_memory()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:12:22.458434Z","iopub.execute_input":"2023-11-23T00:12:22.458961Z","iopub.status.idle":"2023-11-23T00:12:23.224273Z","shell.execute_reply.started":"2023-11-23T00:12:22.458918Z","shell.execute_reply":"2023-11-23T00:12:23.221642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\n%matplotlib inline\nimport gc\nimport os\nimport itertools\nimport pickle\n\nfrom random import choice, choices\nfrom functools import reduce\nfrom tqdm import tqdm\nfrom itertools import cycle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom functools import reduce\nfrom itertools import cycle\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nfrom sklearn import metrics, model_selection, preprocessing, linear_model, ensemble, decomposition, tree\nfrom transformers import BertTokenizer\nimport warnings\n\nimport os\nimport gc\nimport re\nimport random\nfrom collections import Counter, defaultdict\nimport pprint\nimport time\nimport copy\n\n\nimport seaborn as sns\nfrom tqdm.autonotebook import tqdm\n\n# from gensim.models import Word2Vec\nfrom sklearn.preprocessing import LabelEncoder, PowerTransformer, RobustScaler, FunctionTransformer\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD, PCA\nfrom sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.cluster import KMeans\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.impute import SimpleImputer\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:12:23.227559Z","iopub.execute_input":"2023-11-23T00:12:23.227929Z","iopub.status.idle":"2023-11-23T00:12:23.413775Z","shell.execute_reply.started":"2023-11-23T00:12:23.227896Z","shell.execute_reply":"2023-11-23T00:12:23.41137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv')\ntrain_scores = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv')\ntestdf = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:12:23.415878Z","iopub.execute_input":"2023-11-23T00:12:23.41792Z","iopub.status.idle":"2023-11-23T00:12:42.022472Z","shell.execute_reply.started":"2023-11-23T00:12:23.417786Z","shell.execute_reply":"2023-11-23T00:12:42.020607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getEssays(df):\n    # Copy required columns\n    textInputDf = df[['id', 'activity', 'cursor_position', 'text_change']].copy()\n    \n    # Get rid of text inputs that make no change\n    # Note: Shift was unpreditcable so ignored\n    textInputDf = textInputDf[textInputDf.activity != 'Nonproduction']\n\n    # Get how much each Id there is\n    valCountsArr = textInputDf['id'].value_counts(sort=False).values\n\n    # Holds the final index of the previous Id\n    lastIndex = 0\n\n    # Holds all the essays\n    essaySeries = pd.Series()\n\n    # Fills essay series with essays\n    for index, valCount in enumerate(valCountsArr):\n\n        # Indexes down_time at current Id\n        currTextInput = textInputDf[['activity', 'cursor_position', 'text_change']].iloc[lastIndex : lastIndex + valCount]\n\n        # Update the last index\n        lastIndex += valCount\n\n        # Where the essay content will be stored\n        essayText = \"\"\n\n        \n        # Produces the essay\n        for Input in currTextInput.values:\n            \n            # Input[0] = activity\n            # Input[2] = cursor_position\n            # Input[3] = text_change\n            \n            # If activity = Replace\n            if Input[0] == 'Replace':\n                # splits text_change at ' => '\n                replaceTxt = Input[2].split(' => ')\n                \n                # DONT TOUCH\n                essayText = essayText[:Input[1] - len(replaceTxt[1])] + replaceTxt[1] + essayText[Input[1] - len(replaceTxt[1]) + len(replaceTxt[0]):]\n                continue\n\n                \n            # If activity = Paste    \n            if Input[0] == 'Paste':\n                # DONT TOUCH\n                essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n                continue\n\n                \n            # If activity = Remove/Cut\n            if Input[0] == 'Remove/Cut':\n                # DONT TOUCH\n                essayText = essayText[:Input[1]] + essayText[Input[1] + len(Input[2]):]\n                continue\n\n                \n            # If activity = Move...\n            if \"M\" in Input[0]:\n                # Gets rid of the \"Move from to\" text\n                croppedTxt = Input[0][10:]\n                \n                # Splits cropped text by ' To '\n                splitTxt = croppedTxt.split(' To ')\n                \n                # Splits split text again by ', ' for each item\n                valueArr = [item.split(', ') for item in splitTxt]\n                \n                # Move from [2, 4] To [5, 7] = (2, 4, 5, 7)\n                moveData = (int(valueArr[0][0][1:]), int(valueArr[0][1][:-1]), int(valueArr[1][0][1:]), int(valueArr[1][1][:-1]))\n\n                # Skip if someone manages to activiate this by moving to same place\n                if moveData[0] != moveData[2]:\n                    # Check if they move text forward in essay (they are different)\n                    if moveData[0] < moveData[2]:\n                        # DONT TOUCH\n                        essayText = essayText[:moveData[0]] + essayText[moveData[1]:moveData[3]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[3]:]\n                    else:\n                        # DONT TOUCH\n                        essayText = essayText[:moveData[2]] + essayText[moveData[0]:moveData[1]] + essayText[moveData[2]:moveData[0]] + essayText[moveData[1]:]\n                continue\n                \n                \n            # If just input\n            # DONT TOUCH\n            essayText = essayText[:Input[1] - len(Input[2])] + Input[2] + essayText[Input[1] - len(Input[2]):]\n\n            \n        # Sets essay at index  \n        essaySeries[index] = essayText\n     \n    \n    # Sets essay series index to the ids\n    essaySeries.index =  textInputDf['id'].unique()\n    \n    \n    # Returns the essay series\n    return essaySeries","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:12:42.024371Z","iopub.execute_input":"2023-11-23T00:12:42.024844Z","iopub.status.idle":"2023-11-23T00:12:42.044026Z","shell.execute_reply.started":"2023-11-23T00:12:42.024801Z","shell.execute_reply":"2023-11-23T00:12:42.042975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_essays = getEssays(traindf)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:12:42.045543Z","iopub.execute_input":"2023-11-23T00:12:42.046178Z","iopub.status.idle":"2023-11-23T00:22:07.716618Z","shell.execute_reply.started":"2023-11-23T00:12:42.046138Z","shell.execute_reply":"2023-11-23T00:22:07.715114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_essays = getEssays(testdf)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:07.718475Z","iopub.execute_input":"2023-11-23T00:22:07.71888Z","iopub.status.idle":"2023-11-23T00:22:07.732819Z","shell.execute_reply.started":"2023-11-23T00:22:07.718845Z","shell.execute_reply":"2023-11-23T00:22:07.730656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_essaysdf = pd.DataFrame({'id': train_essays.index, 'essay': train_essays.values})\ntest_essaysdf = pd.DataFrame({'id': test_essays.index, 'essay': test_essays.values})","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:07.735241Z","iopub.execute_input":"2023-11-23T00:22:07.735688Z","iopub.status.idle":"2023-11-23T00:22:07.74542Z","shell.execute_reply.started":"2023-11-23T00:22:07.735646Z","shell.execute_reply":"2023-11-23T00:22:07.743987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_data = train_essaysdf.merge(train_scores, on='id')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:07.747015Z","iopub.execute_input":"2023-11-23T00:22:07.748203Z","iopub.status.idle":"2023-11-23T00:22:07.768666Z","shell.execute_reply.started":"2023-11-23T00:22:07.748162Z","shell.execute_reply":"2023-11-23T00:22:07.766429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_vectorizer = CountVectorizer(ngram_range=(1, 2))\nX_tokenizer_train = count_vectorizer.fit_transform(merged_data['essay'])\nX_tokenizer_test = count_vectorizer.transform(test_essaysdf['essay'])\ncount_vectorizer.get_feature_names_out() #ADDED\ny = merged_data['score']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:07.771084Z","iopub.execute_input":"2023-11-23T00:22:07.772557Z","iopub.status.idle":"2023-11-23T00:22:08.748956Z","shell.execute_reply.started":"2023-11-23T00:22:07.772478Z","shell.execute_reply":"2023-11-23T00:22:08.748145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame()\ndf_test = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:08.750188Z","iopub.execute_input":"2023-11-23T00:22:08.751831Z","iopub.status.idle":"2023-11-23T00:22:08.760904Z","shell.execute_reply.started":"2023-11-23T00:22:08.75179Z","shell.execute_reply":"2023-11-23T00:22:08.759356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tokenizer_train = X_tokenizer_train.todense()\nX_tokenizer_test = X_tokenizer_test.todense()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:08.762457Z","iopub.execute_input":"2023-11-23T00:22:08.762776Z","iopub.status.idle":"2023-11-23T00:22:08.774712Z","shell.execute_reply.started":"2023-11-23T00:22:08.762748Z","shell.execute_reply":"2023-11-23T00:22:08.773233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(X_tokenizer_train.shape[1]) : \n    L = list(X_tokenizer_train[:,i])\n    li = [int(x) for x in L ]\n    df_train[f'feature {i}'] = li","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:08.776459Z","iopub.execute_input":"2023-11-23T00:22:08.776828Z","iopub.status.idle":"2023-11-23T00:22:12.347301Z","shell.execute_reply.started":"2023-11-23T00:22:08.776795Z","shell.execute_reply":"2023-11-23T00:22:12.345405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(X_tokenizer_test.shape[1]) : \n    L = list(X_tokenizer_test[:,i])\n    li = [int(x) for x in L ]\n    df_test[f'feature {i}'] = li","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:12.349552Z","iopub.execute_input":"2023-11-23T00:22:12.349944Z","iopub.status.idle":"2023-11-23T00:22:12.462877Z","shell.execute_reply.started":"2023-11-23T00:22:12.349909Z","shell.execute_reply":"2023-11-23T00:22:12.460877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_index = train_essaysdf['id']\ndf_test_index = test_essaysdf['id']","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:12.465136Z","iopub.execute_input":"2023-11-23T00:22:12.465527Z","iopub.status.idle":"2023-11-23T00:22:12.470645Z","shell.execute_reply.started":"2023-11-23T00:22:12.465497Z","shell.execute_reply":"2023-11-23T00:22:12.469579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[:, 'id'] = df_train_index\ndf_test.loc[:, 'id'] = df_test_index","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:12.472005Z","iopub.execute_input":"2023-11-23T00:22:12.472351Z","iopub.status.idle":"2023-11-23T00:22:12.48321Z","shell.execute_reply.started":"2023-11-23T00:22:12.472327Z","shell.execute_reply":"2023-11-23T00:22:12.482315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_agg_fe_df = traindf.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntrain_agg_fe_df.columns = ['_'.join(x) for x in train_agg_fe_df.columns]\ntrain_agg_fe_df = train_agg_fe_df.add_prefix(\"tmp_\")\ntrain_agg_fe_df.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:12.484618Z","iopub.execute_input":"2023-11-23T00:22:12.484943Z","iopub.status.idle":"2023-11-23T00:22:17.412003Z","shell.execute_reply.started":"2023-11-23T00:22:12.484914Z","shell.execute_reply":"2023-11-23T00:22:17.410265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_agg_fe_df = testdf.groupby(\"id\")[['down_time', 'up_time', 'action_time', 'cursor_position', 'word_count']].agg(['mean', 'std', 'min', 'max', 'last', 'first', 'sem', 'median', 'sum'])\ntest_agg_fe_df.columns = ['_'.join(x) for x in test_agg_fe_df.columns]\ntest_agg_fe_df = test_agg_fe_df.add_prefix(\"tmp_\")\ntest_agg_fe_df.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:17.413872Z","iopub.execute_input":"2023-11-23T00:22:17.4143Z","iopub.status.idle":"2023-11-23T00:22:17.441584Z","shell.execute_reply.started":"2023-11-23T00:22:17.414266Z","shell.execute_reply":"2023-11-23T00:22:17.439162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\nclass Preprocessor:\n    \n    def __init__(self, seed):\n        self.seed = seed\n        \n        self.activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n        self.events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n        self.text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n        self.punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n        self.gaps = [1, 2, 3, 5, 10, 20, 50, 100]\n        \n        self.idf = defaultdict(float)\n#         self.gaps = [1, 2]\n    \n    def activity_counts(self, df):\n        tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['activity'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.activities:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n\n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n\n        return ret\n\n\n    def event_counts(self, df, colname):\n        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df[colname].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.events:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n            \n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n\n        return ret\n\n\n    def text_change_counts(self, df):\n        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['text_change'].values):\n            items = list(Counter(li).items())\n            di = dict()\n            for k in self.text_changes:\n                di[k] = 0\n            for item in items:\n                k, v = item[0], item[1]\n                if k in di:\n                    di[k] = v\n            ret.append(di)\n        ret = pd.DataFrame(ret)\n        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n        ret.columns = cols\n\n        cnts = ret.sum(1)\n\n        for col in cols:\n            if col in self.idf.keys():\n                idf = self.idf[col]\n            else:\n                idf = df.shape[0] / (ret[col].sum() + 1)\n                idf = np.log(idf)\n                self.idf[col] = idf\n            \n            ret[col] = 1 + np.log(ret[col] / cnts)\n            ret[col] *= idf\n            \n        return ret\n\n    def match_punctuations(self, df):\n        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n        ret = list()\n        for li in tqdm(tmp_df['down_event'].values):\n            cnt = 0\n            items = list(Counter(li).items())\n            for item in items:\n                k, v = item[0], item[1]\n                if k in self.punctuations:\n                    cnt += v\n            ret.append(cnt)\n        ret = pd.DataFrame({'punct_cnt': ret})\n        return ret\n\n\n    def get_input_words(self, df):\n        tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n        tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n        tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n        tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n        tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n        tmp_df.drop(['text_change'], axis=1, inplace=True)\n        return tmp_df\n    \n    def make_feats(self, df):\n        \n        print(\"Starting to engineer features\")\n        \n        # initialize features dataframe\n        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n        \n        # get shifted features\n        # time shift\n        print(\"Engineering time data\")\n        for gap in self.gaps:\n            print(f\"> for gap {gap}\")\n            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True)\n\n        # cursor position shift\n        print(\"Engineering cursor position data\")\n        for gap in self.gaps:\n            print(f\"> for gap {gap}\")\n            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}'])\n        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True)\n\n        # word count shift\n        print(\"Engineering word count data\")\n        for gap in self.gaps:\n            print(f\"> for gap {gap}\")\n            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}'])\n        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True)\n        \n        # get aggregate statistical features\n        print(\"Engineering statistical summaries for features\")\n        # [(feature name, [ stat summaries to add ])]\n        feats_stat = [\n            ('event_id', ['max']),\n            ('up_time', ['max']),\n            ('action_time', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n            ('activity', ['nunique']),\n            ('down_event', ['nunique']),\n            ('up_event', ['nunique']),\n            ('text_change', ['nunique']),\n            ('cursor_position', ['nunique', 'max', 'quantile', 'sem', 'mean']),\n            ('word_count', ['nunique', 'max', 'quantile', 'sem', 'mean'])]\n        for gap in self.gaps:\n            feats_stat.extend([\n                (f'action_time_gap{gap}', ['max', 'min', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n                (f'cursor_position_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt]),\n                (f'word_count_change{gap}', ['max', 'mean', 'std', 'quantile', 'sem', 'sum', 'skew', pd.DataFrame.kurt])\n            ])\n        \n        pbar = tqdm(feats_stat)\n        for item in pbar:\n            colname, methods = item[0], item[1]\n            for method in methods:\n                pbar.set_postfix()\n                if isinstance(method, str):\n                    method_name = method\n                else:\n                    method_name = method.__name__\n                    \n                pbar.set_postfix(column=colname, method=method_name)\n                tmp_df = df.groupby(['id']).agg({colname: method}).reset_index().rename(columns={colname: f'{colname}_{method_name}'})\n                feats = feats.merge(tmp_df, on='id', how='left')\n\n        # counts\n        print(\"Engineering activity counts data\")\n        tmp_df = self.activity_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering event counts data\")\n        tmp_df = self.event_counts(df, 'down_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        tmp_df = self.event_counts(df, 'up_event')\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering text change counts data\")\n        tmp_df = self.text_change_counts(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n        \n        print(\"Engineering punctuation counts data\")\n        tmp_df = self.match_punctuations(df)\n        feats = pd.concat([feats, tmp_df], axis=1)\n\n        # input words\n        print(\"Engineering input words data\")\n        tmp_df = self.get_input_words(df)\n        feats = pd.merge(feats, tmp_df, on='id', how='left')\n\n        # compare feats\n        print(\"Engineering ratios data\")\n        feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n        feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']\n        \n        print(\"Done!\")\n        return feats","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:17.446661Z","iopub.execute_input":"2023-11-23T00:22:17.447085Z","iopub.status.idle":"2023-11-23T00:22:17.501511Z","shell.execute_reply.started":"2023-11-23T00:22:17.447023Z","shell.execute_reply":"2023-11-23T00:22:17.499093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = Preprocessor(seed=42)\n\nprint(\"Engineering features for training data\")\n\nother_train_feats = preprocessor.make_feats(traindf)\n\nprint()\nprint(\"-\"*25)\nprint(\"Engineering features for test data\")\nprint(\"-\"*25)\nother_test_feats = preprocessor.make_feats(testdf)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:22:17.503867Z","iopub.execute_input":"2023-11-23T00:22:17.504354Z","iopub.status.idle":"2023-11-23T00:26:49.269689Z","shell.execute_reply.started":"2023-11-23T00:22:17.504312Z","shell.execute_reply":"2023-11-23T00:26:49.266776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_all = pd.DataFrame()\ndf_test_all = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:49.272621Z","iopub.execute_input":"2023-11-23T00:26:49.273022Z","iopub.status.idle":"2023-11-23T00:26:49.281487Z","shell.execute_reply.started":"2023-11-23T00:26:49.272988Z","shell.execute_reply":"2023-11-23T00:26:49.278877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_all = df_train.merge(train_agg_fe_df,on='id')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:49.28334Z","iopub.execute_input":"2023-11-23T00:26:49.28378Z","iopub.status.idle":"2023-11-23T00:26:49.304443Z","shell.execute_reply.started":"2023-11-23T00:26:49.283741Z","shell.execute_reply":"2023-11-23T00:26:49.30209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_all = df_test.merge(test_agg_fe_df,on='id')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:49.306085Z","iopub.execute_input":"2023-11-23T00:26:49.306587Z","iopub.status.idle":"2023-11-23T00:26:49.322523Z","shell.execute_reply.started":"2023-11-23T00:26:49.306547Z","shell.execute_reply":"2023-11-23T00:26:49.320548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def q1(x):\n    return x.quantile(0.25)\ndef q3(x):\n    return x.quantile(0.75)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:49.324996Z","iopub.execute_input":"2023-11-23T00:26:49.325543Z","iopub.status.idle":"2023-11-23T00:26:49.333727Z","shell.execute_reply.started":"2023-11-23T00:26:49.325498Z","shell.execute_reply":"2023-11-23T00:26:49.332021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AGGREGATIONS = ['count', 'mean', 'std', 'min', 'max', 'first', 'last', 'sem', q1, 'median', q3, 'skew', pd.DataFrame.kurt, 'sum']\n\ndef split_essays_into_sentences(df):\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['sent'] = essay_df['essay'].apply(lambda x: re.split('\\\\.|\\\\?|\\\\!',str(x)))\n    essay_df = essay_df.explode('sent')\n    essay_df['sent'] = essay_df['sent'].apply(lambda x: x.replace('\\n','').strip())\n    # Number of characters in sentences\n    essay_df['sent_len'] = essay_df['sent'].apply(lambda x: len(x))\n    # Number of words in sentences\n    essay_df['sent_word_count'] = essay_df['sent'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.columns.tolist()].reset_index(drop=True)\n    return essay_df\n\ndef compute_sentence_aggregations(df):\n    sent_agg_df = pd.concat(\n        [df[['id','sent_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','sent_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    )\n    sent_agg_df.columns = ['_'.join(x) for x in sent_agg_df.columns]\n    sent_agg_df['id'] = sent_agg_df.index\n    sent_agg_df = sent_agg_df.reset_index(drop=True)\n    sent_agg_df.drop(columns=[\"sent_word_count_count\"], inplace=True)\n    sent_agg_df = sent_agg_df.rename(columns={\"sent_len_count\":\"sent_count\"})\n    return sent_agg_df\n\ndef split_essays_into_paragraphs(df):\n    essay_df = df\n    essay_df['id'] = essay_df.index\n    essay_df['paragraph'] = essay_df['essay'].apply(lambda x: str(x).split('\\n'))\n    essay_df = essay_df.explode('paragraph')\n    # Number of characters in paragraphs\n    essay_df['paragraph_len'] = essay_df['paragraph'].apply(lambda x: len(x)) \n    # Number of words in paragraphs\n    essay_df['paragraph_word_count'] = essay_df['paragraph'].apply(lambda x: len(x.split(' ')))\n    essay_df = essay_df[essay_df.paragraph_len!=0].reset_index(drop=True)\n    return essay_df\n\ndef compute_paragraph_aggregations(df):\n    paragraph_agg_df = pd.concat(\n        [df[['id','paragraph_len']].groupby(['id']).agg(AGGREGATIONS), df[['id','paragraph_word_count']].groupby(['id']).agg(AGGREGATIONS)], axis=1\n    ) \n    paragraph_agg_df.columns = ['_'.join(x) for x in paragraph_agg_df.columns]\n    paragraph_agg_df['id'] = paragraph_agg_df.index\n    paragraph_agg_df = paragraph_agg_df.reset_index(drop=True)\n    paragraph_agg_df.drop(columns=[\"paragraph_word_count_count\"], inplace=True)\n    paragraph_agg_df = paragraph_agg_df.rename(columns={\"paragraph_len_count\":\"paragraph_count\"})\n    return paragraph_agg_df","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:49.335616Z","iopub.execute_input":"2023-11-23T00:26:49.336467Z","iopub.status.idle":"2023-11-23T00:26:49.352911Z","shell.execute_reply.started":"2023-11-23T00:26:49.336436Z","shell.execute_reply":"2023-11-23T00:26:49.350525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sent_df = split_essays_into_sentences(train_essaysdf)\ntrain_sent_agg_df = compute_sentence_aggregations(train_sent_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:49.357784Z","iopub.execute_input":"2023-11-23T00:26:49.358179Z","iopub.status.idle":"2023-11-23T00:26:55.425809Z","shell.execute_reply.started":"2023-11-23T00:26:49.358149Z","shell.execute_reply":"2023-11-23T00:26:55.424207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paragraph_df = split_essays_into_paragraphs(train_essaysdf)\ntrain_paragraph_agg_df = compute_paragraph_aggregations(train_paragraph_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:26:55.427853Z","iopub.execute_input":"2023-11-23T00:26:55.428271Z","iopub.status.idle":"2023-11-23T00:27:01.463416Z","shell.execute_reply.started":"2023-11-23T00:26:55.428233Z","shell.execute_reply":"2023-11-23T00:27:01.460652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sent_agg_df = compute_sentence_aggregations(split_essays_into_sentences(test_essaysdf))\ntest_paragraph_agg_df = compute_paragraph_aggregations(split_essays_into_paragraphs(test_essaysdf))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.466423Z","iopub.execute_input":"2023-11-23T00:27:01.466901Z","iopub.status.idle":"2023-11-23T00:27:01.545089Z","shell.execute_reply.started":"2023-11-23T00:27:01.466865Z","shell.execute_reply":"2023-11-23T00:27:01.542874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paragraph_agg_df.loc[:, 'id'] = df_train_index\ntrain_sent_agg_df.loc[:, 'id'] = df_train_index","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.54766Z","iopub.execute_input":"2023-11-23T00:27:01.548094Z","iopub.status.idle":"2023-11-23T00:27:01.558237Z","shell.execute_reply.started":"2023-11-23T00:27:01.548022Z","shell.execute_reply":"2023-11-23T00:27:01.55702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_paragraph_agg_df.loc[:, 'id'] = df_test_index\ntest_sent_agg_df.loc[:, 'id'] = df_test_index","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.559823Z","iopub.execute_input":"2023-11-23T00:27:01.560165Z","iopub.status.idle":"2023-11-23T00:27:01.573553Z","shell.execute_reply.started":"2023-11-23T00:27:01.560137Z","shell.execute_reply":"2023-11-23T00:27:01.571354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_feats = pd.DataFrame()\nnew_test_feats = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.57547Z","iopub.execute_input":"2023-11-23T00:27:01.57601Z","iopub.status.idle":"2023-11-23T00:27:01.587872Z","shell.execute_reply.started":"2023-11-23T00:27:01.575966Z","shell.execute_reply":"2023-11-23T00:27:01.585401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train_feats = train_paragraph_agg_df.merge(df_train_all,on='id')\nnew_train_feats = new_train_feats.merge(train_sent_agg_df,on='id')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.590022Z","iopub.execute_input":"2023-11-23T00:27:01.590517Z","iopub.status.idle":"2023-11-23T00:27:01.641068Z","shell.execute_reply.started":"2023-11-23T00:27:01.590475Z","shell.execute_reply":"2023-11-23T00:27:01.638822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_test_feats = test_paragraph_agg_df.merge(df_test_all,on='id')\nnew_test_feats = new_test_feats.merge(test_sent_agg_df,on='id')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.64296Z","iopub.execute_input":"2023-11-23T00:27:01.643422Z","iopub.status.idle":"2023-11-23T00:27:01.679033Z","shell.execute_reply.started":"2023-11-23T00:27:01.643385Z","shell.execute_reply":"2023-11-23T00:27:01.676646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feats = pd.DataFrame()\ntest_feats = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.681389Z","iopub.execute_input":"2023-11-23T00:27:01.681808Z","iopub.status.idle":"2023-11-23T00:27:01.689214Z","shell.execute_reply.started":"2023-11-23T00:27:01.681766Z","shell.execute_reply":"2023-11-23T00:27:01.688009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feats = new_train_feats.merge(other_train_feats,on='id')\ntest_feats = new_test_feats.merge(other_test_feats,on='id')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.692732Z","iopub.execute_input":"2023-11-23T00:27:01.693331Z","iopub.status.idle":"2023-11-23T00:27:01.75432Z","shell.execute_reply.started":"2023-11-23T00:27:01.693284Z","shell.execute_reply":"2023-11-23T00:27:01.752137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\n\nfor logs in [traindf, testdf]:\n    logs['up_time_lagged'] = logs.groupby('id')['up_time'].shift(1).fillna(logs['down_time'])\n    logs['time_diff'] = abs(logs['down_time'] - logs['up_time_lagged']) / 1000\n\n    group = logs.groupby('id')['time_diff']\n    largest_lantency = group.max()\n    smallest_lantency = group.min()\n    median_lantency = group.median()\n    initial_pause = logs.groupby('id')['down_time'].first() / 1000\n    pauses_half_sec = group.apply(lambda x: ((x > 0.5) & (x < 1)).sum())\n    pauses_1_sec = group.apply(lambda x: ((x > 1) & (x < 1.5)).sum())\n    pauses_1_half_sec = group.apply(lambda x: ((x > 1.5) & (x < 2)).sum())\n    pauses_2_sec = group.apply(lambda x: ((x > 2) & (x < 3)).sum())\n    pauses_3_sec = group.apply(lambda x: (x > 3).sum())\n\n    data.append(pd.DataFrame({\n        'id': logs['id'].unique(),\n        'largest_lantency': largest_lantency,\n        'smallest_lantency': smallest_lantency,\n        'median_lantency': median_lantency,\n        'initial_pause': initial_pause,\n        'pauses_half_sec': pauses_half_sec,\n        'pauses_1_sec': pauses_1_sec,\n        'pauses_1_half_sec': pauses_1_half_sec,\n        'pauses_2_sec': pauses_2_sec,\n        'pauses_3_sec': pauses_3_sec,\n    }).reset_index(drop=True))\n\ntrain_eD592674, test_eD592674 = data\n\ntrain_feats = train_feats.merge(train_eD592674, on='id', how='left')\ntest_feats = test_feats.merge(test_eD592674, on='id', how='left')\ntrain_feats = train_feats.merge(train_scores, on='id', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:01.756139Z","iopub.execute_input":"2023-11-23T00:27:01.756472Z","iopub.status.idle":"2023-11-23T00:27:10.252453Z","shell.execute_reply.started":"2023-11-23T00:27:01.756444Z","shell.execute_reply":"2023-11-23T00:27:10.250628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\ntrain_feats['score_class'] = le.fit_transform(train_feats['score'])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:10.25516Z","iopub.execute_input":"2023-11-23T00:27:10.255619Z","iopub.status.idle":"2023-11-23T00:27:10.264366Z","shell.execute_reply.started":"2023-11-23T00:27:10.255585Z","shell.execute_reply":"2023-11-23T00:27:10.263137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col = ['score']\n\ndrop_cols = ['id', 'score_class']\ntrain_cols = list()\n\ntrain_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]\n\ntrain_cols.__len__(), target_col.__len__()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:10.265805Z","iopub.execute_input":"2023-11-23T00:27:10.26628Z","iopub.status.idle":"2023-11-23T00:27:10.28002Z","shell.execute_reply.started":"2023-11-23T00:27:10.266251Z","shell.execute_reply":"2023-11-23T00:27:10.27786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_cols = train_feats.columns[train_feats.isna().any()].tolist()\nnan_cols","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:10.282413Z","iopub.execute_input":"2023-11-23T00:27:10.28373Z","iopub.status.idle":"2023-11-23T00:27:10.324597Z","shell.execute_reply.started":"2023-11-23T00:27:10.283674Z","shell.execute_reply":"2023-11-23T00:27:10.322709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in nan_cols:\n    mode_value_train = train_feats[col].mode()[0]  # In case there are multiple modes, choose the first one\n    train_feats[col].fillna(mode_value_train, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:10.327309Z","iopub.execute_input":"2023-11-23T00:27:10.327715Z","iopub.status.idle":"2023-11-23T00:27:10.345166Z","shell.execute_reply.started":"2023-11-23T00:27:10.327683Z","shell.execute_reply":"2023-11-23T00:27:10.343679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in test_feats.columns[test_feats.isna().any()].tolist():\n    # Find the most frequent value in the training set for the current feature\n    most_frequent_value_train = train_feats[col].mode()[0]\n    \n    # Fill missing values in the test set with the most frequent value from the training set\n    test_feats[col].fillna(most_frequent_value_train, inplace=True)\n\ntrain_feats.shape, test_feats.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:10.347985Z","iopub.execute_input":"2023-11-23T00:27:10.348567Z","iopub.status.idle":"2023-11-23T00:27:10.488131Z","shell.execute_reply.started":"2023-11-23T00:27:10.348515Z","shell.execute_reply":"2023-11-23T00:27:10.486454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_feats.columns[train_feats.isna().any()].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:10.490577Z","iopub.execute_input":"2023-11-23T00:27:10.491085Z","iopub.status.idle":"2023-11-23T00:27:11.012473Z","shell.execute_reply.started":"2023-11-23T00:27:10.491021Z","shell.execute_reply":"2023-11-23T00:27:11.010893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_values_test = test_feats.columns[test_feats.isna().any()].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:11.014723Z","iopub.execute_input":"2023-11-23T00:27:11.015263Z","iopub.status.idle":"2023-11-23T00:27:11.050469Z","shell.execute_reply.started":"2023-11-23T00:27:11.015219Z","shell.execute_reply":"2023-11-23T00:27:11.048506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_memory()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_dict = {}\nscores = []\n\ntest_predict_list = []\nbest_params = {'boosting_type': 'gbdt', \n               'metric': 'rmse',\n               'reg_alpha': 0.003188447814669599, \n               'reg_lambda': 0.0010228604507564066, \n               'colsample_bytree': 0.5420247656839267, \n               'subsample': 0.9778252382803456, \n               'feature_fraction': 0.8,\n               'bagging_freq': 1,\n               'bagging_fraction': 0.75,\n               'learning_rate': 0.01716485155812008, \n               'num_leaves': 19, \n               'min_child_samples': 46,\n               'verbosity': -1,\n               'random_state': 42,\n               'n_estimators': 500,\n               'device_type': 'cpu'}\n\nfor i in range(5): \n    kf = model_selection.KFold(n_splits=10, random_state=42 + i, shuffle=True)\n\n    oof_valid_preds = np.zeros(train_feats.shape[0], )\n\n    X_test = test_feats[train_cols]\n\n\n    for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n\n        print(\"==-\"* 50)\n        print(\"Fold : \", fold)\n\n        X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n        X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n\n        print(\"Trian :\", X_train.shape, y_train.shape)\n        print(\"Valid :\", X_valid.shape, y_valid.shape)\n\n        params = {\n            \"objective\": \"regression\",\n            \"metric\": \"rmse\",\n            'random_state': 42,\n            \"n_estimators\" : 12001,\n            \"verbosity\": -1,\n            \"device_type\": \"cpu\",\n            **best_params\n        }\n\n        model = lgb.LGBMRegressor(**params)\n\n        early_stopping_callback = lgb.early_stopping(200, first_metric_only=True, verbose=False)\n        verbose_callback = lgb.callback.record_evaluation({})\n\n        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],  \n                  callbacks=[early_stopping_callback, verbose_callback],\n        )\n\n        valid_predict = model.predict(X_valid)\n        oof_valid_preds[valid_idx] = valid_predict\n\n        test_predict = model.predict(X_test)\n        test_predict_list.append(test_predict)\n\n        score = metrics.mean_squared_error(y_valid, valid_predict, squared=False)\n        print(\"Fold RMSE Score : \", score)\n\n        models_dict[f'{fold}_{i}'] = model\n\n\n    oof_score = metrics.mean_squared_error(train_feats[target_col], oof_valid_preds, squared=False)\n    scores.append(oof_score)\n    print(\"OOF RMSE Score : \", oof_score)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:27:11.055033Z","iopub.execute_input":"2023-11-23T00:27:11.055423Z","iopub.status.idle":"2023-11-23T00:39:37.382338Z","shell.execute_reply.started":"2023-11-23T00:27:11.05539Z","shell.execute_reply":"2023-11-23T00:39:37.380713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances_values = np.asarray([model.feature_importances_ for model in models_dict.values()]).mean(axis=0)\nfeature_importance_df = pd.DataFrame({'name': train_cols, 'importance': feature_importances_values})\n\nfeature_importance_df = feature_importance_df.sort_values('importance', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:37.384216Z","iopub.execute_input":"2023-11-23T00:39:37.384568Z","iopub.status.idle":"2023-11-23T00:39:37.408021Z","shell.execute_reply.started":"2023-11-23T00:39:37.384537Z","shell.execute_reply":"2023-11-23T00:39:37.405912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(scores)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:37.410724Z","iopub.execute_input":"2023-11-23T00:39:37.411202Z","iopub.status.idle":"2023-11-23T00:39:37.421545Z","shell.execute_reply.started":"2023-11-23T00:39:37.411165Z","shell.execute_reply":"2023-11-23T00:39:37.419937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\n\nax = sns.barplot(data=feature_importance_df.head(30), x='name', y='importance')\nax.set_title(f\"Mean feature importances\")\nax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=90)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:37.425119Z","iopub.execute_input":"2023-11-23T00:39:37.425442Z","iopub.status.idle":"2023-11-23T00:39:37.982032Z","shell.execute_reply.started":"2023-11-23T00:39:37.425417Z","shell.execute_reply":"2023-11-23T00:39:37.981355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_feats['score'] = np.mean(test_predict_list, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:37.983256Z","iopub.execute_input":"2023-11-23T00:39:37.983693Z","iopub.status.idle":"2023-11-23T00:39:37.98951Z","shell.execute_reply.started":"2023-11-23T00:39:37.983668Z","shell.execute_reply":"2023-11-23T00:39:37.98762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub2 = test_feats[['id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:37.991884Z","iopub.execute_input":"2023-11-23T00:39:37.992271Z","iopub.status.idle":"2023-11-23T00:39:38.004031Z","shell.execute_reply.started":"2023-11-23T00:39:37.992237Z","shell.execute_reply":"2023-11-23T00:39:38.001517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"clean_memory()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:38.007125Z","iopub.execute_input":"2023-11-23T00:39:38.007655Z","iopub.status.idle":"2023-11-23T00:39:38.520755Z","shell.execute_reply.started":"2023-11-23T00:39:38.007611Z","shell.execute_reply":"2023-11-23T00:39:38.519283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub1.rename(columns={'score': 'score_1'}, inplace=True)\nsub2.rename(columns={'score': 'score_2'}, inplace=True)\nsubmission = pd.merge(sub1, sub2, on='id')\nsubmission['score'] = ((submission['score_1'] * (1/2)) +  #LGBM + NN (Weighted search for \"print(W)\")\n                       (submission['score_2'] * (1/2)))   #LGBM Public\n\nsubmission_final = submission[['id', 'score']]","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:38.522911Z","iopub.execute_input":"2023-11-23T00:39:38.523377Z","iopub.status.idle":"2023-11-23T00:39:38.541122Z","shell.execute_reply.started":"2023-11-23T00:39:38.523335Z","shell.execute_reply":"2023-11-23T00:39:38.538981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_final.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:38.542873Z","iopub.execute_input":"2023-11-23T00:39:38.543312Z","iopub.status.idle":"2023-11-23T00:39:38.555705Z","shell.execute_reply.started":"2023-11-23T00:39:38.543273Z","shell.execute_reply":"2023-11-23T00:39:38.553545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_final","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:39:38.560538Z","iopub.execute_input":"2023-11-23T00:39:38.560931Z","iopub.status.idle":"2023-11-23T00:39:38.575828Z","shell.execute_reply.started":"2023-11-23T00:39:38.5609Z","shell.execute_reply":"2023-11-23T00:39:38.574305Z"},"trusted":true},"execution_count":null,"outputs":[]}]}